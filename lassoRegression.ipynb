{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
      "         0.01990842, -0.01764613],\n",
      "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
      "        -0.06832974, -0.09220405],\n",
      "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
      "         0.00286377, -0.02593034],\n",
      "       ...,\n",
      "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
      "        -0.04687948,  0.01549073],\n",
      "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
      "         0.04452837, -0.02593034],\n",
      "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
      "        -0.00421986,  0.00306441]]), 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
      "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
      "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
      "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
      "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
      "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
      "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
      "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
      "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
      "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
      "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
      "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
      "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
      "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
      "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
      "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
      "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
      "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
      "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
      "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
      "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
      "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
      "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
      "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
      "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
      "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
      "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
      "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
      "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
      "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
      "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
      "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
      "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
      "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
      "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
      "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
      "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
      "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
      "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
      "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
      "       220.,  57.]), 'frame': None, 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, T-Cells (a type of white blood cells)\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, thyroid stimulating hormone\\n      - s5      ltg, lamotrigine\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)', 'feature_names': ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], 'data_filename': '/Users/callanduffy/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/data/diabetes_data.csv.gz', 'target_filename': '/Users/callanduffy/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/data/diabetes_target.csv.gz'}\n",
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, T-Cells (a type of white blood cells)\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, thyroid stimulating hormone\n",
      "      - s5      ltg, lamotrigine\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diab = load_diabetes()\n",
    "print(diab)\n",
    "print(diab.DESCR)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n"
     ]
    }
   ],
   "source": [
    "#print(diab.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n"
     ]
    }
   ],
   "source": [
    "#print(diab.target.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03807591  0.05068012  0.06169621 ... -0.00259226  0.01990842\n",
      "  -0.01764613]\n",
      " [-0.00188202 -0.04464164 -0.05147406 ... -0.03949338 -0.06832974\n",
      "  -0.09220405]\n",
      " [ 0.08529891  0.05068012  0.04445121 ... -0.00259226  0.00286377\n",
      "  -0.02593034]\n",
      " ...\n",
      " [ 0.04170844  0.05068012 -0.01590626 ... -0.01107952 -0.04687948\n",
      "   0.01549073]\n",
      " [-0.04547248 -0.04464164  0.03906215 ...  0.02655962  0.04452837\n",
      "  -0.02593034]\n",
      " [-0.04547248 -0.04464164 -0.0730303  ... -0.03949338 -0.00421986\n",
      "   0.00306441]]\n"
     ]
    }
   ],
   "source": [
    "#print(diab.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -0.         -152.23582501  597.3997159   209.2340184  -138.64270077\n",
      "   -0.         -176.5883705     0.          550.4975621    66.84364085]\n",
      "[112.64185933 189.40884709 118.70132142 148.59369969 184.92071316\n",
      " 131.94523337 158.19532517 226.47640394 152.83283597 209.2518883\n",
      " 256.99105868 227.64886896 130.96813413 139.40311506  63.94815008\n",
      " 188.31190711 109.74125544 104.69688737 154.49565833 108.74577713\n",
      " 124.85840386 120.01862948 180.38914908 153.95026911  67.81000392\n",
      "  51.8738669   98.1857839   71.50186508  74.03939519 158.74846332\n",
      "  96.6989413  105.73774138 219.4491695  112.6191607  118.19132318\n",
      " 200.63207801 246.41734592 113.42646877  80.87143214 233.13167517\n",
      " 146.80053867  75.16982611  78.39859455 260.97063349 108.529286\n",
      " 148.23707146 239.17899893 153.45412421 206.1058073  265.85276074\n",
      " 141.36382138 205.68026918 180.65059195 148.19091514 136.08319581\n",
      " 179.71427108 156.81188771 164.29229792 236.16045809  85.7285607\n",
      "  60.60246094 141.86092971 176.20838692 208.68891829  91.10516476\n",
      "  61.73420235 211.14194441 296.67049944 272.47455265  97.94495027\n",
      " 242.65440188 222.3611017  132.4229982  261.36863941 116.14504504\n",
      " 171.25261362 167.31720106 225.75233333  52.03920514 128.96752657\n",
      " 116.32756197 183.3242661  148.9718106  125.88164743 192.56180878\n",
      "  76.68387154 123.28578146 228.67092623 211.56570983 153.37909268\n",
      " 163.97254204 205.48540014 209.80179554 161.65812206  65.47004352\n",
      " 117.5544895   70.14045145  96.85651011 130.30794371 119.11395349\n",
      " 115.45098818 225.22043979  83.30669945 172.9463165  189.67596959\n",
      "  70.72905529 156.39774028 137.28654302 144.37409092  78.71360326\n",
      " 168.5120932 ]\n",
      "[129. 283.  88. 219. 142.  60. 197. 236. 134. 248. 275. 268.  59. 214.\n",
      "  77. 202. 183. 108. 302.  64. 168. 214. 198. 100. 143.  90. 102. 128.\n",
      "  59. 131.  54.  31. 225. 179. 160.  68. 281. 103.  42. 217. 172.  55.\n",
      "  65. 132.  53. 172. 259.  85.  52. 277.  88. 272. 292.  90. 219.  67.\n",
      " 206. 245. 272.  53.  63.  25. 242. 155. 137.  47. 296. 258. 243. 125.\n",
      " 274. 270.  49. 220. 178. 128. 124. 195.  72.  50.  68. 167. 154.  83.\n",
      "  78.  51. 132. 246. 121. 210. 235. 288. 275.  55.  70. 109.  48.  65.\n",
      " 124. 182. 253.  99. 200. 141. 229. 134. 118. 230.  61.  60. 131.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "x_train, x_test, y_train, y_test = train_test_split(diab['data'], diab['target'], random_state = 2212)\n",
    "lasso_reg = Lasso(alpha = 0.1)\n",
    "lasso_reg.fit(x_train, y_train)\n",
    "print(lasso_reg.coef_)\n",
    "pred = lasso_reg.predict(x_test)\n",
    "#print(pred)\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the above are the coeffiecents and the of the model, the prediction and the actual results.\n",
    "As you can see it has made age, s2 and s4 converge to zero. In the next cell i will get the R^2 value of test and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set: -0.17204251740656495\n",
      "training set: 0.08173505375592416\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "#for test set\n",
    "r2 = r2_score(pred, y_test)\n",
    "print(\"test set: \"+str(r2))\n",
    "train_pred = lasso_reg.predict(x_train)\n",
    "r3 = r2_score(train_pred, y_train)\n",
    "print(\"training set: \"+str(r3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the training and test R2 for the Lasso model using the default parameters?\n",
    "as you can see from above test set = -0.17204251740656495\n",
    "this isnt a good score so it doesnt fit too well\n",
    "the training set gives a slightly better score of 0.08173505375592416\n",
    "this means it fits better however it is not close to 1 so cant be considered reliable either.\n",
    "\n",
    "How many features does this model use?\n",
    "the model only uses 7 of the original 10, it uses\n",
    "sex, bmi, bp, s1, s3, s5 and s6, the others age, s2 and s4 turn to zero for their coeffiecents. \n",
    "\n",
    "What are the names of those features?\n",
    "answered above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 11)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "diab2 = np.genfromtxt(\"diabetes.data\", delimiter=\"\")\n",
    "#print(diab2)\n",
    "diab2 = np.delete(diab2, 0, 0)\n",
    "print(diab2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.delete(diab2, [0,1,2,3,4,5,6,7,8,9],1)\n",
    "#print(labels)\n",
    "data = np.delete(diab2, [10], 1)\n",
    "#print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.09479698 -21.74628005   6.50782774   0.89383132  -1.05128514\n",
      "   0.56270638   0.45441997   8.1001466   69.18308612   0.44030795]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "z_train, z_test, v_train, v_test = train_test_split(data, labels, random_state = 2212)\n",
    "lasso_test = Lasso(alpha = 0.1)\n",
    "lasso_test.fit(z_train, v_train)\n",
    "print(lasso_test.coef_)\n",
    "pred = lasso_test.predict(z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: -0.08778417290065166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(pred, v_test)\n",
    "print(\"test score: \"+str(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.21775254604727223\n"
     ]
    }
   ],
   "source": [
    "pred2 = lasso_test.predict(z_train)\n",
    "r3 = r2_score(pred2, v_train)\n",
    "print(\"train score: \"+str(r3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as you can see the training score increases from around 0.08 to around 0.22, this is a dramatic increase. this is also true for the test score increasing from -0.17 to -0.08, again a noticeable increase. In this case also features are active, no coeffiencents have turned to zero, meaning they all have an affect. the most interesting thing I spotted was how coeffeicent[7] and [6] essentially swap relevance. 6 practically goes to zero whereas 7 increases a lot from zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "z, z_t, v, v_t = train_test_split(data, labels, random_state = 2212)\n",
    "\n",
    "scalerData = StandardScaler(with_mean=0, with_std=1).fit(z)\n",
    "#print(z)\n",
    "z = scalerData.transform(z)\n",
    "z_t = scalerData.transform(z_t)\n",
    "#print(z)\n",
    "v = scalerData.fit_transform(v)\n",
    "v_t = scalerData.transform(v_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.          0.35002204  0.07261507 -0.         -0.\n",
      " -0.05929727  0.          0.28606072  0.        ]\n",
      "test score: -0.6184376996648411\n",
      "training score: -0.3965266007052828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "new_lasso = Lasso(alpha=0.1)\n",
    "new_lasso.fit(z, v)\n",
    "print(new_lasso.coef_)\n",
    "pred = new_lasso.predict(z_t)\n",
    "r2 = r2_score(pred, v_t)\n",
    "\n",
    "train = new_lasso.predict(z)\n",
    "\n",
    "r3 = r2_score(train, v)\n",
    "print(\"test score: \"+str(r2))\n",
    "print(\"training score: \"+str(r3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the results of this scaled set are odd. I didnt believe them at first which is why I scaled the data twice. however this did not work either. I thought before standardising that the scores would be closer to the set from sklearn however theyre actually worse than either. 6 coeffiecents have gone to zero and they dont match any of the other coeffiecents. the scores have also worsened. the training score is negative, indicating it's not working. however, the only way to make the scores better would be to make the alpha value smaller. so I've decided to use my own method for R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0780585]\n"
     ]
    }
   ],
   "source": [
    "#RSS and TSS for training data\n",
    "rss_sum = 0\n",
    "tss_sum = 0\n",
    "mean = np.mean(v)\n",
    "for i in range(len(train)):\n",
    "    rss_sum =+ (v[i]-train[i])**2\n",
    "    tss_sum =+ (v[i]-mean)**2\n",
    "rsquared = 1 - (rss_sum/tss_sum)\n",
    "print(rsquared)\n",
    "#clearly shows a worse score, will now try on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-36.39963557]\n"
     ]
    }
   ],
   "source": [
    "rss = 0\n",
    "tss = 0\n",
    "mean = np.mean(v_t)\n",
    "for i in range(len(pred)):\n",
    "    rss =+ (v_t[i]-pred[i])**2\n",
    "    tss =+ (v_t[i]-mean)**2\n",
    "rsquared = 1 - (rss/tss)\n",
    "print(rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ive ended with worse scores than when i started to clearly this hasnt worked.\n",
    "what I've noticed is that the scores are almost the same when the mean is applied to the predicted set.\n",
    "\n",
    "to answer q8\n",
    "Are your current results closer to those in item 3 or item 6? \n",
    "the results using the sklearn method are closer to item 6, the results using the code in cells 86 and 90 are not close to either.\n",
    "Notice that a priori you would expect your current results to be closer to those in item 3, since the reason for different results in items 3 and 6 was that the former were for normalized data while the latter were for the original data. Is this expectation confirmed?\n",
    "If not, why?\n",
    "I think the standardScaler doesnt work for sklearn very well, I was expecting the results to be close to 3 not further from both. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varying the parameter α in the Lasso, plot the test R2 vs the number of features used (i.e., those with non-zero coefficients). Try to make your plot as pretty as possible. (Obviously, it’s subjective.) Which point on the curve do you prefer? (There is no unique correct answer to this question.) Give a brief explanation of your preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -0.          -28.54132799  578.9742935   151.21782363   -0.\n",
      "   -6.74856901 -135.62911641    0.          475.15053117    1.87091883]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.datasets import load_diabetes\n",
    "diab = load_diabetes()\n",
    "x_train, x_test, y_train, y_test = train_test_split(diab['data'], diab['target'], random_state = 2212)\n",
    "lasso_reg = Lasso(alpha = 0.25)\n",
    "lasso_reg.fit(x_train, y_train)\n",
    "print(lasso_reg.coef_)\n",
    "pred = lasso_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "alpha = [3, 2, 1, 0.75,0.5, 0.25, 0.1, 0.01]\n",
    "num_of_features = [0, 2, 2, 3, 4, 7, 6,10]\n",
    "plt.plot(alpha, num_of_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Obviously, it’s subjective.) Which point on the curve do you prefer? (There is no unique correct answer to this question.) Give a brief explanation of your preference.\n",
    "I prefer 0.25, it incorporates the most features before it goes up exponentially to ten. \n",
    "However I think 0.1 is also the most practical as it appears as a dip so it could be that it is the most optimal in the graph. Obviously numbers from 3 and 0.01 are not useful as they either use all of the features or none. the numbers from 3-0.5 frankly dont use enough features to be accurate. anything below 0.25 will use too many features. this makes it hugely inaccurate, as unuseful features are used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the regularization parameter for the Lasso using cross-validation on the training set. Train the Lasso on the whole training set using the chosen values of the parameters. Report the resulting training and test R2 and the number of features used. (As before, you are allowed to use any scikit-learn functions.)\n",
    "I've used the sklearn version as im not sure I normalised the raw version properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callanduffy/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02985075 0.03030303 0.01515152 0.01515152 0.03030303]\n",
      "0.024151967435549527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callanduffy/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02985075 0.03030303 0.01515152 0.01515152 0.03030303]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callanduffy/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02985075 0.03030303 0.01515152 0.01515152 0.03030303]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callanduffy/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02985075 0.03030303 0.01515152 0.01515152 0.03030303]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callanduffy/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02985075 0.03030303 0.01515152 0.01515152 0.03030303]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callanduffy/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02985075 0.03030303 0.01515152 0.01515152 0.03030303]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callanduffy/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02985075 0.03030303 0.01515152 0.01515152 0.03030303]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callanduffy/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02985075 0.03030303 0.01515152 0.01515152 0.03030303]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callanduffy/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01492537 0.01515152 0.01515152 0.         0.01515152]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/callanduffy/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.01515152]\n",
      "0.2882882882882883\n",
      "0.001\n",
      "0.2214890779007238\n",
      "-0.0850443985067606\n",
      "[ -25.5210853  -232.57053902  602.27988228  259.36316221 -802.394194\n",
      "  386.6414082   141.93601592  228.26504651  777.54471289  104.66252849]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "diabetes = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, random_state=2212)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso()\n",
    "score_best =0\n",
    "alpha_best = 0\n",
    "for C in [0.001,0.001,0.01,0.1,0.25,0.5,0.75,1,2,3]:\n",
    "    svm = SVC(C=10**C, kernel='linear')\n",
    "    score = cross_val_score(svm, x_train, y_train, cv=5)\n",
    "    print(score)\n",
    "    score = np.mean(score)\n",
    "    if score > score_best:\n",
    "        print(score)\n",
    "        score_best = score\n",
    "        alpha_best = C\n",
    "\n",
    "svm = SVC(C = alpha_best)\n",
    "svm.fit(X_test, y_test)\n",
    "print(svm.score(X_test, y_test))\n",
    "lasso_reg = Lasso(alpha = alpha_best)\n",
    "lasso_reg.fit(x_train, y_train)\n",
    "pred = lasso_reg.predict(x_test)\n",
    "train = lasso_reg.predict(x_train)\n",
    "r2 = r2_score(train, y_train)\n",
    "r3 = r2_score(pred, y_test)\n",
    "print(alpha_best)\n",
    "print(r2)\n",
    "print(r3)\n",
    "print(lasso_reg.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the cross_val_score approach only gives me the first c value cross_val_score doesnt change when c changes, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training set that you obtained in item 5 into two parts: the calibration set of size 99 and the rest of the training set (the training set proper). Use your birthday (in the format DDMM) as random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "diab2 = np.genfromtxt(\"diabetes.data\", delimiter=\"\")\n",
    "diab2 = np.delete(diab2, 0, 0)\n",
    "labels = np.delete(diab2, [0,1,2,3,4,5,6,7,8,9],1)\n",
    "data = np.delete(diab2, [10], 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, random_state=2212)\n",
    "x_train = X_train[:232]\n",
    "x_train_proper = X_train[232:331]\n",
    "Y_train = y_train[:232]\n",
    "y_train_proper = y_train[232:331]\n",
    "print(y_train_proper.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_train_proper = scaler.transform(x_train_proper)\n",
    "x_test = scaler.transform(X_test)\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_train_proper = scaler.transform(y_train_proper)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonConformScores = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
